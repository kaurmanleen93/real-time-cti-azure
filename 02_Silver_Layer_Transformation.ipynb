{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d12a00-9931-4fdb-af64-55b1b035d681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Notebook: 02_Silver_Layer_Transformation\n",
    "# Purpose: Clean, normalize, and enrich EV range data from Bronze to Silver\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 1: Imports\n",
    "# ------------------------------------------------------------------------------\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "print(\"✅ Libraries imported\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 2: Define paths\n",
    "# ------------------------------------------------------------------------------\n",
    "bronze_path = \"/mnt/cti/bronze/ev_data\"\n",
    "silver_path = \"/mnt/cti/silver/ev_data\"\n",
    "\n",
    "print(f\"\uD83D\uDCC2 Bronze path: {bronze_path}\")\n",
    "print(f\"\uD83D\uDCC2 Silver path: {silver_path}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 3: Read Bronze layer\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDCD6 Reading from Bronze layer...\")\n",
    "\n",
    "df_bronze = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "bronze_count = df_bronze.count()\n",
    "print(f\"✅ Loaded {bronze_count} records from Bronze\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCCB Sample Bronze data:\")\n",
    "display(df_bronze.limit(10))\n",
    "\n",
    "print(\"\\n\uD83D\uDCDC Bronze schema:\")\n",
    "df_bronze.printSchema()\n",
    "\n",
    "# Helper: quick column-exists check\n",
    "def has_col(df, col_name: str) -> bool:\n",
    "    return col_name in df.columns\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 4: Basic normalization / standardization\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83E\uDDF9 Standardizing key text fields (Make, Model)...\")\n",
    "\n",
    "df_silver = df_bronze\n",
    "\n",
    "# Normalize Make\n",
    "if has_col(df_silver, \"Make\"):\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"Make_Clean\",\n",
    "        F.upper(F.trim(F.col(\"Make\")))\n",
    "    )\n",
    "\n",
    "# Normalize Model\n",
    "if has_col(df_silver, \"Model\"):\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"Model_Clean\",\n",
    "        F.upper(F.trim(F.col(\"Model\")))\n",
    "    )\n",
    "\n",
    "# If you have City / County columns, standardize them too (if present)\n",
    "if has_col(df_silver, \"City\"):\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"City_Clean\",\n",
    "        F.initcap(F.trim(F.col(\"City\")))\n",
    "    )\n",
    "\n",
    "if has_col(df_silver, \"County\"):\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"County_Clean\",\n",
    "        F.initcap(F.trim(F.col(\"County\")))\n",
    "    )\n",
    "\n",
    "print(\"✅ Text fields standardized (where present)\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 5: Range-related features (if Electric_Range exists)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDD22 Deriving range-related fields...\")\n",
    "\n",
    "range_col = \"Electric_Range\" if has_col(df_silver, \"Electric_Range\") else None\n",
    "\n",
    "if range_col is not None:\n",
    "    # Ensure Electric_Range is integer and non-negative\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"Electric_Range_Int\",\n",
    "        F.when(F.col(range_col).isNotNull(), F.col(range_col).cast(\"int\"))\n",
    "         .otherwise(F.lit(None).cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    # Flag if range is zero\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"range_is_zero\",\n",
    "        F.when(F.col(\"Electric_Range_Int\") == 0, F.lit(True)).otherwise(F.lit(False))\n",
    "    )\n",
    "\n",
    "    # Range usable for analysis (exclude negatives)\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"range_for_analysis\",\n",
    "        F.when(F.col(\"Electric_Range_Int\") >= 0, F.col(\"Electric_Range_Int\"))\n",
    "         .otherwise(F.lit(None).cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    # Simple range bucket for analysis\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"range_bucket_km\",\n",
    "        F.when(F.col(\"Electric_Range_Int\") <= 0, F.lit(\"0 or Unknown\"))\n",
    "         .when(F.col(\"Electric_Range_Int\") <= 100, F.lit(\"1–100 km\"))\n",
    "         .when(F.col(\"Electric_Range_Int\") <= 200, F.lit(\"101–200 km\"))\n",
    "         .when(F.col(\"Electric_Range_Int\") <= 300, F.lit(\"201–300 km\"))\n",
    "         .when(F.col(\"Electric_Range_Int\") <= 400, F.lit(\"301–400 km\"))\n",
    "         .otherwise(F.lit(\"400+ km\"))\n",
    "    )\n",
    "\n",
    "    print(\"✅ Range fields and buckets created\")\n",
    "else:\n",
    "    print(\"⚠️ Column 'Electric_Range' not found – skipping range feature engineering\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 6: EV type / group (if such a column exists)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDE97 Deriving EV group (if possible)...\")\n",
    "\n",
    "# Common column names for EV type in WA dataset variants\n",
    "ev_type_cols = [\"Electric_Vehicle_Type\", \"EV_Type\", \"ev_group\"]\n",
    "\n",
    "ev_type_col = None\n",
    "for c in ev_type_cols:\n",
    "    if has_col(df_silver, c):\n",
    "        ev_type_col = c\n",
    "        break\n",
    "\n",
    "if ev_type_col is not None:\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"ev_group\",\n",
    "        F.when(F.upper(F.col(ev_type_col)).like(\"%BATTERY%\"), \"BEV\")\n",
    "         .when(F.upper(F.col(ev_type_col)).like(\"%PLUG-IN%\"), \"PHEV\")\n",
    "         .otherwise(F.lit(\"Other_EV\"))\n",
    "    )\n",
    "    print(f\"✅ EV group derived from column '{ev_type_col}'\")\n",
    "else:\n",
    "    print(\"⚠️ No EV type column found – 'ev_group' not derived\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 7: Geo-related sanity checks (if latitude/longitude exist)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83C\uDF0D Validating geo coordinates (if present)...\")\n",
    "\n",
    "if has_col(df_silver, \"latitude\") and has_col(df_silver, \"longitude\"):\n",
    "    df_silver = df_silver.withColumn(\n",
    "        \"latitude_valid\",\n",
    "        F.when((F.col(\"latitude\") >= -90) & (F.col(\"latitude\") <= 90), F.lit(True))\n",
    "         .otherwise(F.lit(False))\n",
    "    ).withColumn(\n",
    "        \"longitude_valid\",\n",
    "        F.when((F.col(\"longitude\") >= -180) & (F.col(\"longitude\") <= 180), F.lit(True))\n",
    "         .otherwise(F.lit(False))\n",
    "    )\n",
    "    print(\"✅ Geo validation flags added\")\n",
    "else:\n",
    "    print(\"⚠️ latitude/longitude not found – skipping geo validation\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 8: Deduplicate by record_id (carried from Bronze)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDD0D Deduplicating by record_id...\")\n",
    "\n",
    "if has_col(df_silver, \"record_id\"):\n",
    "    before_dedup = df_silver.count()\n",
    "    df_silver = df_silver.dropDuplicates([\"record_id\"])\n",
    "    after_dedup = df_silver.count()\n",
    "\n",
    "    print(f\"✅ Deduplication complete:\")\n",
    "    print(f\"   Before: {before_dedup}\")\n",
    "    print(f\"   After : {after_dedup}\")\n",
    "    print(f\"   Removed: {before_dedup - after_dedup} duplicate records\")\n",
    "else:\n",
    "    print(\"⚠️ 'record_id' column not found – no deduplication performed\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 9: Preview Silver dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDCCB Sample of Silver candidate data:\")\n",
    "display(\n",
    "    df_silver.select(\n",
    "        *[c for c in df_silver.columns if c in [\n",
    "            \"record_id\",\n",
    "            \"Model_Year\",\n",
    "            \"Make\",\n",
    "            \"Model\",\n",
    "            \"Make_Clean\",\n",
    "            \"Model_Clean\",\n",
    "            \"Electric_Range\",\n",
    "            \"Electric_Range_Int\",\n",
    "            \"range_for_analysis\",\n",
    "            \"range_bucket_km\",\n",
    "            \"ev_group\",\n",
    "            \"City_Clean\",\n",
    "            \"County_Clean\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"latitude_valid\",\n",
    "            \"longitude_valid\",\n",
    "            \"ingestion_timestamp\",\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"day\",\n",
    "            \"source\"\n",
    "        ]]\n",
    "    ).limit(20)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 10: Write to Silver Delta Lake (full overwrite)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDCBE Writing to Silver Delta Lake (overwrite mode)...\")\n",
    "\n",
    "(\n",
    "    df_silver\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")              # full refresh to avoid MERGE issues\n",
    "        .partitionBy(\"year\", \"month\")   # day often optional at Silver\n",
    "        .save(silver_path)\n",
    ")\n",
    "\n",
    "print(\"✅ Silver table written successfully\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 11: Enable Change Data Feed on Silver\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDD04 Enabling Change Data Feed on Silver table...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE delta.`{silver_path}`\n",
    "    SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ CDC enabled on Silver layer\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CELL 12: Verify Silver table and basic stats\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n\uD83D\uDCCA Verifying Silver layer...\")\n",
    "\n",
    "df_silver_verify = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "total_silver = df_silver_verify.count()\n",
    "print(f\"✅ Total Silver records: {total_silver}\")\n",
    "\n",
    "if has_col(df_silver_verify, \"ev_group\"):\n",
    "    print(\"\\nBy EV Group:\")\n",
    "    df_silver_verify.groupBy(\"ev_group\").count().orderBy(F.col(\"count\").desc()).show()\n",
    "\n",
    "if has_col(df_silver_verify, \"range_bucket_km\"):\n",
    "    print(\"\\nBy Range Bucket:\")\n",
    "    df_silver_verify.groupBy(\"range_bucket_km\").count().orderBy(F.col(\"count\").desc()).show()\n",
    "\n",
    "if has_col(df_silver_verify, \"Make_Clean\"):\n",
    "    print(\"\\nTop 10 Makes:\")\n",
    "    df_silver_verify.groupBy(\"Make_Clean\").count().orderBy(F.col(\"count\").desc()).show(10)\n",
    "\n",
    "print(\"\\n\uD83C\uDF89 Silver Layer Transformation Complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Silver_Layer_Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}